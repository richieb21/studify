{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "\n",
    "# Get the video ID of youtube video from url\n",
    "def extract_video_id(url):\n",
    "    if \"youtube.com\" in url:\n",
    "        return url.split(\"v=\")[-1].split(\"&\")[0]\n",
    "    elif \"youtu.be\" in url:\n",
    "        return url.split(\"/\")[-1]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    \n",
    "def load_youtube_transcript(url):\n",
    "    try:\n",
    "        video_id = extract_video_id(url)\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec, pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Retrieve API Key from .env file\n",
    "load_dotenv()\n",
    "open_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Initialize OpenAI Client\n",
    "client = OpenAI(api_key=open_api_key)\n",
    "\n",
    "# Time to split the transcript into chunks and store in a vector store\n",
    "def collect_transcript(transcript):\n",
    "    text = \"\"\n",
    "    for text_obj in transcript:\n",
    "        text += text_obj[\"text\"] + \" \"\n",
    "\n",
    "    return text\n",
    "\n",
    "def split_text(text, max_length=500):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=max_length,  # The maximum size of each chunk\n",
    "    chunk_overlap=200,  # Overlap between chunks to maintain context\n",
    "    )\n",
    "\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dimensions = 1536\n",
    "index_name = \"youtube-transcript-index\"\n",
    "\n",
    "# Get Pinecone API Key\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize the vector store\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=dimensions,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert the embedded vector\n",
    "def upsert_vector(text, embedding):\n",
    "    index.upsert([(text, embedding)])\n",
    "\n",
    "def query_embedding(query_text):\n",
    "    query_embedding = get_embedding(query_text)\n",
    "    result = index.query(vector=[query_embedding], top_k=5)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Youtube Transcript and store in Pinecone\n",
    "def load_youtube_transcript_and_store(url):\n",
    "    transcript = load_youtube_transcript(url)\n",
    "    chunks = split_text(collect_transcript(transcript))\n",
    "\n",
    "    for chunk in chunks:\n",
    "        embedding = get_embedding(chunk)\n",
    "        upsert_vector(chunk, embedding)\n",
    "\n",
    "# Combine all the documents matched with a query into a single document\n",
    "def combine_documents(documents):\n",
    "    combined_text = \"\"\n",
    "    all_matches = documents[\"matches\"]\n",
    "    for match in all_matches:\n",
    "        combined_text += match[\"id\"] + \"\\n\"\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_query(query_text):\n",
    "    # Simulate the result of querying embeddings (you would need to implement this part)\n",
    "    result = query_embedding(query_text)\n",
    "    documents = combine_documents(result)\n",
    "\n",
    "    # Construct the prompt manually\n",
    "    system_message = f\"\"\"You are a helpful AI teacher that specializes in whatever subject I give you readings of. \n",
    "    I will provide you with YouTube video transcripts and you will answer questions based on the content. \n",
    "    Here is the relevant content for the question:\\n\\n {documents} \\n\\n Only use information given from the transcript, if you do not have enough context to answer the question, say 'I do not have enough information to answer the question.'\"\"\"\n",
    "    \n",
    "    question_message = f\"Answer the following question: {query_text}\"\n",
    "\n",
    "    # Use the OpenAI API to get the response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": question_message}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    # Extract the response content\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer, documents\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Based on the provided transcript, here are some steps and concepts to consider when implementing your own B-trees:\\n\\n1. **Understand the Node Structure**: Each node in a B-tree of degree \\\\( t \\\\) (where \\\\( t \\\\) is the minimum degree) can have at most \\\\( 2t - 1 \\\\) keys and \\\\( 2t \\\\) children. For a B-tree of degree 4, each node can have up to 3 keys and 4 children.\\n\\n2. **Insertion Process**:\\n   - Start with an empty tree.\\n   - Insert keys one by one.\\n   - If a node exceeds the maximum number of keys, split the node and promote the middle key to the parent node.\\n\\n3. **Node Structure**:\\n   - Each node contains keys and child pointers.\\n   - For a degree 4 B-tree, each node will have 3 keys and 4 child pointers.\\n\\n4. **Handling Overflow**:\\n   - When inserting a key into a node that already has the maximum number of keys, split the node into two nodes and move the middle key up to the parent node.\\n   - If the parent node also has the maximum number of keys, repeat the splitting process up the tree.\\n\\n5. **B+ Trees**:\\n   - In B+ trees, only the leaf nodes contain pointers to the actual records.\\n   - Internal nodes only contain keys and child pointers, not record pointers.\\n\\n6. **Relating to Databases**:\\n   - B-trees and B+ trees are used in databases for indexing to improve search efficiency.\\n\\nHere is a simplified outline of the steps to implement a B-tree:\\n\\n1. **Define the Node Structure**:\\n   ```python\\n   class BTreeNode:\\n       def __init__(self, t, leaf=False):\\n           self.t = t  # Minimum degree (defines the range for number of keys)\\n           self.keys = []  # List of keys\\n           self.children = []  # List of child pointers\\n           self.leaf = leaf  # True if leaf node, else False\\n   ```\\n\\n2. **Insert Function**:\\n   ```python\\n   class BTree:\\n       def __init__(self, t):\\n           self.root = BTreeNode(t, True)\\n           self.t = t\\n\\n       def insert(self, key):\\n           root = self.root\\n           if len(root.keys) == (2 * self.t) - 1:\\n               new_root = BTreeNode(self.t, False)\\n               new_root.children.append(self.root)\\n               self.split_child(new_root, 0)\\n               self.root = new_root\\n           self._insert_non_full(self.root, key)\\n\\n       def split_child(self, parent, i):\\n           t = self.t\\n           node = parent.children[i]\\n           new_node = BTreeNode(t, node.leaf)\\n           parent.children.insert(i + 1, new_node)\\n           parent.keys.insert(i, node.keys[t - 1])\\n\\n           new_node.keys = node.keys[t:(2 * t) - 1]\\n           node.keys = node.keys[0:t - 1]\\n\\n           if not node.leaf:\\n               new_node.children = node.children[t:(2 * t)]\\n               node.children = node.children[0:t]\\n\\n       def _insert_non_full(self, node, key):\\n           i = len(node.keys) - 1\\n           if node.leaf:\\n               node.keys.append(None)\\n               while i >= 0 and key < node.keys[i]:\\n                   node.keys[i + 1] = node.keys[i]\\n                   i -= 1\\n               node.keys[i + 1] = key\\n           else:\\n               while i >= 0 and key < node.keys[i]:\\n                   i -= 1\\n               i += 1\\n               if len(node.children[i].keys) == (2 * self.t) - 1:\\n                   self.split_child(node, i)\\n                   if key > node.keys[i]:\\n                       i += 1\\n               self._insert_non_full(node.children[i], key)\\n   ```\\n\\nThis is a basic implementation outline. You would need to add additional methods for deletion, searching, and handling edge cases to have a fully functional B-tree.', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=aZjYr87r1b8\"\n",
    "\n",
    "query = input()\n",
    "response, documents = get_response_from_query(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-rag-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
